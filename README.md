# WMAD: Weakly-supervised Multi-view Anomaly Detection

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

WMAD is a deep learning framework for multi-view anomaly detection, specifically designed for weakly-supervised scenarios (i.e., with limited labeled samples).

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Benchmark Results](#benchmark-results)
- [Project Structure](#project-structure)
- [Usage Examples](#usage-examples)
- [Model Overview](#model-overview)
- [Data Format](#data-format)
- [Citation](#citation)
- [License](#license)

## âœ¨ Features

- **Multi-view Learning**: Handles multiple views (data sources) simultaneously for anomaly detection
- **Weakly-supervised Learning**: Trains effectively with limited labeled samples
- **Contrastive Learning**: Enhances detection performance through cross-view contrastive learning
- **Flexible Configuration**: Provides rich hyperparameter configuration options
- **Easy to Use**: Simple API with comprehensive example code
- **Comprehensive Comparison**: Includes comparison with 5+ baseline methods

## ğŸ“¦ Installation

### Method 1: Install with pip (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/wmad.git
cd wmad

# Install dependencies
pip install -r requirements.txt

# Install WMAD package
pip install -e .
```

### Method 2: Install from source

```bash
git clone https://github.com/yourusername/wmad.git
cd wmad
python setup.py install
```

### Dependencies

Main dependencies:
- Python >= 3.7
- NumPy >= 1.21.0
- PyTorch >= 1.9.0
- scikit-learn >= 1.0.0
- pandas >= 1.3.0
- scipy >= 1.7.0

**Note**: This project depends on the `deepod` library. You need to install it separately:

```bash
# If deepod folder is included in the project
cd deepod
pip install -e .

# Or install from official source
pip install deepod
```

## ğŸš€ Quick Start

### 1. Run Test Notebook

We provide a test notebook with synthetic data (10,000 samples) including **comparison with 5 baseline methods**:

```bash
jupyter notebook test_wmad.ipynb
```

The notebook includes:
- Data generation and visualization
- Training MEAD and 5 baseline methods (DeepSAD, RoSAS, DevNet, FeaWAD, PReNet)
- Performance comparison with metrics and plots
- ROC and Precision-Recall curve comparisons

### 2. Basic Usage Example

```python
import numpy as np
from wmad.models import MEAD
from wmad.data_utils import inject_unlabeled_labels

# Prepare data (three views)
X1_train, X2_train, X3_train = ...  # Training data
X1_val, X2_val, X3_val = ...        # Validation data
y_train = ...                        # Labels (0=normal, 1=anomaly)

# Inject unlabeled samples (simulate weakly-supervised scenario)
y_train_weakly = inject_unlabeled_labels(
    y_train, 
    unlabeled_ratio=0.9,  # 90% unlabeled
    min_anomalies=10,
    random_state=42
)

# Create and train model
model = MEAD(
    epochs=50,
    batch_size=64,
    lr=1e-4,
    rep_dim=32,
    device='cpu',
    verbose=2
)

model.fit(
    X1_train, X2_train, X3_train, y_train_weakly,
    X1_val, X2_val, X3_val, y_val
)

# Predict
scores = model.decision_function(X1_test, X2_test, X3_test)
```

## ğŸ“Š Benchmark Results

We compare MEAD with several state-of-the-art baseline methods on synthetic and real-world datasets:

### Baseline Methods

- **DeepSAD**: Semi-supervised Deep SVDD
- **RoSAS**: Robust Semi-supervised Anomaly Detection
- **DevNet**: Deviation Networks for Anomaly Detection  
- **FeaWAD**: Feature Encoding with Wasserstein Distance
- **PReNet**: Piecewise Linear Regression Networks

### Performance on Synthetic Dataset (10K samples, 5% anomalies, 90% unlabeled)

| Method | AUC-ROC | AUC-PR | Training Time |
|--------|---------|--------|---------------|
| **MEAD** | **0.9XXX** | **0.8XXX** | XX.Xs |
| DeepSAD | 0.9XXX | 0.8XXX | XX.Xs |
| RoSAS | 0.9XXX | 0.7XXX | XX.Xs |
| DevNet | 0.9XXX | 0.8XXX | XX.Xs |
| FeaWAD | 0.9XXX | 0.8XXX | XX.Xs |
| PReNet | 0.9XXX | 0.7XXX | XX.Xs |

*Note: Run `test_wmad.ipynb` to reproduce these results*

### Key Observations

- âœ“ MEAD achieves **competitive or superior** performance compared to baselines
- âœ“ Effectively leverages **multi-view information** for better detection
- âœ“ **Robust** under different unlabeled ratios (90%, 99%, 99.9%)
- âœ“ Efficient training with reasonable computational cost

## ğŸ“ Project Structure

```
wmad/
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ setup.py                  # Installation script
â”œâ”€â”€ test_wmad.ipynb          # Test notebook (with synthetic data & baseline comparison)
â”œâ”€â”€ experiment_main.py        # Main experiment script
â”œâ”€â”€ wmad/                     # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/              # Model implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mead.py          # MEAD model
â”‚   â”‚   â””â”€â”€ base_model.py    # Base model class
â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ similarity.py    # Similarity computation
â”‚   â””â”€â”€ data_utils.py        # Data processing utilities
â””â”€â”€ deepod/                   # Third-party dependency (deep anomaly detection library)
```

## ğŸ’¡ Usage Examples

### Example 1: Using Custom Data

```python
from wmad.models import MEAD
from sklearn.preprocessing import MinMaxScaler

# Load your data
X1, X2, X3, y = load_your_data()

# Normalize data
scaler1, scaler2, scaler3 = MinMaxScaler(), MinMaxScaler(), MinMaxScaler()
X1 = scaler1.fit_transform(X1)
X2 = scaler2.fit_transform(X2)
X3 = scaler3.fit_transform(X3)

# Train model
model = MEAD(epochs=50, device='cuda')  # Use GPU
model.fit(X1_train, X2_train, X3_train, y_train,
          X1_val, X2_val, X3_val, y_val)

# Evaluate
from sklearn.metrics import roc_auc_score
scores = model.decision_function(X1_test, X2_test, X3_test)
auc = roc_auc_score(y_test, scores)
print(f"AUC-ROC: {auc:.4f}")
```

### Example 2: Hyperparameter Tuning

```python
# Configure model parameters
model = MEAD(
    epochs=100,
    batch_size=64,
    lr=1e-4,
    rep_dim=32,
    hidden_dims_view1='256,128,64',
    hidden_dims_view2='256,128,64',
    hidden_dims_view3='256,128,64',
    eta1=0.0001,           # Weight for normal samples
    eta2=0.0001,           # Weight for anomalous samples
    lambda_=0.005,         # Weight for contrastive loss
    beta_=1,               # Weight for SVDD loss
    k=30,                  # Number of negative samples
    temperature=1.0,       # Temperature parameter
    contrastive_mode='cross_view_cross_sample',
    similarity_mode='distance',
    device='cuda',
    verbose=2
)
```

## ğŸ”¬ Model Overview

### MEAD (Multi-view Enhanced Anomaly Detection)

MEAD is a deep learning model specifically designed for multi-view anomaly detection with the following key features:

1. **Multi-view Encoders**: Learns independent representations for each view
2. **Deep SVDD Loss**: Maps normal samples near hypersphere center
3. **Contrastive Learning**: Leverages cross-view information to enhance detection
4. **Weakly-supervised Support**: Handles large amounts of unlabeled samples

### Loss Function

The total loss consists of two components:

```
L_total = Î² Ã— L_SVDD + Î» Ã— L_contrast
```

Where:
- `L_SVDD`: Deep SVDD loss for clustering normal samples around the hypersphere center
- `L_contrast`: Contrastive learning loss for enhancing cross-view consistency
- `Î²`, `Î»`: Balance parameters

## ğŸ“Š Data Format

### Input Data Format

WMAD expects data in the following format:

- **X1, X2, X3**: numpy arrays with shape `(n_samples, n_features_view_i)`
- **y**: numpy array with shape `(n_samples,)`
  - 0: Normal samples
  - 1: Anomalous samples
  - NaN: Unlabeled samples (for weakly-supervised scenarios)

### Example Data Structure

```python
# View 1: 20 features
X1.shape  # (10000, 20)

# View 2: 15 features
X2.shape  # (10000, 15)

# View 3: 10 features
X3.shape  # (10000, 10)

# Labels
y.shape   # (10000,)
# Contains: 5700 normal samples, 300 anomalous samples, 4000 unlabeled samples (NaN)
```

## ğŸ”§ Reproduce Experiments

Run complete experiments (including multiple fraud ratios and unlabeled ratios):

```bash
python experiment_main.py
```

Experiment configuration can be modified in `experiment_main.py`:

```python
FRAUD_RATIOS = [0.05, 0.04, 0.03, 0.02, 0.01]  # Fraud ratios
UNLABELED_RATIOS = [0.9, 0.99, 0.999]          # Unlabeled ratios
N_SPLITS = 5                                    # K-fold cross-validation
EPOCHS = 50                                     # Training epochs
```

## ğŸ“– Citation

If you use WMAD in your research, please cite:

```bibtex
@software{wmad2024,
  title={WMAD: Weakly-supervised Multi-view Anomaly Detection},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/wmad}
}
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit Issues or Pull Requests.

## ğŸ“§ Contact

For questions, please contact:

- Submit GitHub Issue
- Email: your.email@example.com

## ğŸ™ Acknowledgments

- This project is built upon the [DeepOD](https://github.com/xuhongzuo/DeepOD) library
- Thanks to all contributors for their support

---

**Note**: This is a research project for learning and research purposes. Please conduct thorough testing and validation before using it in production environments.

